{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hai\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 34,\n",
       " '?': 19,\n",
       " 'apple': 32,\n",
       " 'back': 5,\n",
       " 'bathroom': 6,\n",
       " 'bedroom': 35,\n",
       " 'daniel': 37,\n",
       " 'discarded': 31,\n",
       " 'down': 13,\n",
       " 'dropped': 15,\n",
       " 'football': 29,\n",
       " 'garden': 33,\n",
       " 'got': 16,\n",
       " 'grabbed': 8,\n",
       " 'hallway': 10,\n",
       " 'in': 4,\n",
       " 'is': 17,\n",
       " 'john': 27,\n",
       " 'journeyed': 30,\n",
       " 'kitchen': 12,\n",
       " 'left': 14,\n",
       " 'mary': 1,\n",
       " 'milk': 7,\n",
       " 'moved': 36,\n",
       " 'no': 25,\n",
       " 'office': 2,\n",
       " 'picked': 26,\n",
       " 'put': 11,\n",
       " 'sandra': 9,\n",
       " 'the': 28,\n",
       " 'there': 21,\n",
       " 'to': 3,\n",
       " 'took': 20,\n",
       " 'travelled': 23,\n",
       " 'up': 18,\n",
       " 'went': 22,\n",
       " 'yes': 24}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 34,\n",
       " '?': 19,\n",
       " 'apple': 32,\n",
       " 'back': 5,\n",
       " 'bathroom': 6,\n",
       " 'bedroom': 35,\n",
       " 'daniel': 37,\n",
       " 'discarded': 31,\n",
       " 'down': 13,\n",
       " 'dropped': 15,\n",
       " 'football': 29,\n",
       " 'garden': 33,\n",
       " 'got': 16,\n",
       " 'grabbed': 8,\n",
       " 'hallway': 10,\n",
       " 'in': 4,\n",
       " 'is': 17,\n",
       " 'john': 27,\n",
       " 'journeyed': 30,\n",
       " 'kitchen': 12,\n",
       " 'left': 14,\n",
       " 'mary': 1,\n",
       " 'milk': 7,\n",
       " 'moved': 36,\n",
       " 'no': 25,\n",
       " 'office': 2,\n",
       " 'picked': 26,\n",
       " 'put': 11,\n",
       " 'sandra': 9,\n",
       " 'the': 28,\n",
       " 'there': 21,\n",
       " 'to': 3,\n",
       " 'took': 20,\n",
       " 'travelled': 23,\n",
       " 'up': 18,\n",
       " 'went': 22,\n",
       " 'yes': 24}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " word_index = tokenizer.word_index\n",
    " word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 28, 35, 34],\n",
       "       [ 0,  0,  0, ..., 28, 33, 34],\n",
       "       [ 0,  0,  0, ..., 28, 33, 34],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 28, 32, 34],\n",
       "       [ 0,  0,  0, ..., 28, 33, 34],\n",
       "       [ 0,  0,  0, ..., 32, 21, 34]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 27,  4, 28, 12, 19],\n",
       "       [17, 27,  4, 28, 12, 19],\n",
       "       [17, 27,  4, 28, 33, 19],\n",
       "       ...,\n",
       "       [17,  1,  4, 28, 35, 19],\n",
       "       [17,  9,  4, 28, 33, 19],\n",
       "       [17,  1,  4, 28, 33, 19]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 497., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.8579 - acc: 0.4956 - val_loss: 0.6946 - val_acc: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.7016 - acc: 0.5046 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.6960 - acc: 0.4961 - val_loss: 0.6932 - val_acc: 0.5010\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.6950 - acc: 0.5033 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 7s 731us/step - loss: 0.6947 - acc: 0.5040 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.6946 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 0.6948 - acc: 0.5002 - val_loss: 0.6940 - val_acc: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 7s 714us/step - loss: 0.6945 - acc: 0.5012 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.6946 - acc: 0.4964 - val_loss: 0.6940 - val_acc: 0.4980\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.6930 - acc: 0.5119 - val_loss: 0.6938 - val_acc: 0.5050\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 7s 714us/step - loss: 0.6874 - acc: 0.5439 - val_loss: 0.6789 - val_acc: 0.5780\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 7s 740us/step - loss: 0.6335 - acc: 0.6413 - val_loss: 0.5381 - val_acc: 0.7520\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 7s 741us/step - loss: 0.5416 - acc: 0.7448 - val_loss: 0.4534 - val_acc: 0.8110\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 0.4809 - acc: 0.7876 - val_loss: 0.4279 - val_acc: 0.8070\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 8s 768us/step - loss: 0.4383 - acc: 0.8170 - val_loss: 0.3954 - val_acc: 0.8280\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 7s 750us/step - loss: 0.4130 - acc: 0.8286 - val_loss: 0.3904 - val_acc: 0.8180\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.3953 - acc: 0.8364 - val_loss: 0.3773 - val_acc: 0.8280\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 7s 737us/step - loss: 0.3818 - acc: 0.8441 - val_loss: 0.3761 - val_acc: 0.8400\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 8s 764us/step - loss: 0.3651 - acc: 0.8510 - val_loss: 0.3620 - val_acc: 0.8390\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.3556 - acc: 0.8523 - val_loss: 0.3787 - val_acc: 0.8220\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.3404 - acc: 0.8585 - val_loss: 0.3762 - val_acc: 0.8360\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 8s 802us/step - loss: 0.3387 - acc: 0.8577 - val_loss: 0.3524 - val_acc: 0.8350\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 7s 727us/step - loss: 0.3317 - acc: 0.8597 - val_loss: 0.3597 - val_acc: 0.8350\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 7s 741us/step - loss: 0.3315 - acc: 0.8573 - val_loss: 0.3646 - val_acc: 0.8340\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 0.3212 - acc: 0.8635 - val_loss: 0.3426 - val_acc: 0.8430\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.3178 - acc: 0.8628 - val_loss: 0.3441 - val_acc: 0.8360\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 7s 700us/step - loss: 0.3151 - acc: 0.8649 - val_loss: 0.3391 - val_acc: 0.8430\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 7s 709us/step - loss: 0.3148 - acc: 0.8632 - val_loss: 0.3447 - val_acc: 0.8360\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 7s 723us/step - loss: 0.3076 - acc: 0.8662 - val_loss: 0.3629 - val_acc: 0.8250\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.3096 - acc: 0.8627 - val_loss: 0.3485 - val_acc: 0.8320\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.3101 - acc: 0.8643 - val_loss: 0.3470 - val_acc: 0.8370\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 0.3040 - acc: 0.8650 - val_loss: 0.3498 - val_acc: 0.8280\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 0.3039 - acc: 0.8643 - val_loss: 0.3389 - val_acc: 0.8340\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 0.3052 - acc: 0.8684 - val_loss: 0.3433 - val_acc: 0.8360\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 8s 774us/step - loss: 0.2984 - acc: 0.8662 - val_loss: 0.3577 - val_acc: 0.8390\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 8s 783us/step - loss: 0.3030 - acc: 0.8672 - val_loss: 0.3325 - val_acc: 0.8410\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 8s 785us/step - loss: 0.2989 - acc: 0.8674 - val_loss: 0.3408 - val_acc: 0.8400\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.2934 - acc: 0.8698 - val_loss: 0.3372 - val_acc: 0.8470\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.2991 - acc: 0.8687 - val_loss: 0.3308 - val_acc: 0.8490\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 8s 782us/step - loss: 0.2956 - acc: 0.8702 - val_loss: 0.3385 - val_acc: 0.8370\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.2957 - acc: 0.8703 - val_loss: 0.3344 - val_acc: 0.8400\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.2927 - acc: 0.8712 - val_loss: 0.3463 - val_acc: 0.8410\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 7s 736us/step - loss: 0.2962 - acc: 0.8725 - val_loss: 0.3303 - val_acc: 0.8450\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 7s 738us/step - loss: 0.2920 - acc: 0.8702 - val_loss: 0.3843 - val_acc: 0.8350\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 8s 818us/step - loss: 0.2908 - acc: 0.8696 - val_loss: 0.3557 - val_acc: 0.8410\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 7s 700us/step - loss: 0.2922 - acc: 0.8713 - val_loss: 0.3343 - val_acc: 0.8440\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.2899 - acc: 0.8734 - val_loss: 0.3358 - val_acc: 0.8410\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 0.2888 - acc: 0.8698 - val_loss: 0.3377 - val_acc: 0.8380\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.2898 - acc: 0.8713 - val_loss: 0.3372 - val_acc: 0.8430\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 7s 711us/step - loss: 0.2903 - acc: 0.8720 - val_loss: 0.3325 - val_acc: 0.8430\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 7s 704us/step - loss: 0.2875 - acc: 0.8733 - val_loss: 0.3443 - val_acc: 0.8380\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 7s 694us/step - loss: 0.2913 - acc: 0.8694 - val_loss: 0.3480 - val_acc: 0.8420\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2876 - acc: 0.8715 - val_loss: 0.3296 - val_acc: 0.8440\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.2845 - acc: 0.8737 - val_loss: 0.3431 - val_acc: 0.8370\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.2877 - acc: 0.8718 - val_loss: 0.3684 - val_acc: 0.8390\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.2874 - acc: 0.8747 - val_loss: 0.3506 - val_acc: 0.8410\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.2838 - acc: 0.8720 - val_loss: 0.3399 - val_acc: 0.8420\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.2870 - acc: 0.8741 - val_loss: 0.3665 - val_acc: 0.8400\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 683us/step - loss: 0.2889 - acc: 0.8753 - val_loss: 0.3281 - val_acc: 0.8410\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.2837 - acc: 0.8763 - val_loss: 0.3386 - val_acc: 0.8430\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.2849 - acc: 0.8748 - val_loss: 0.3516 - val_acc: 0.8510\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.2863 - acc: 0.8705 - val_loss: 0.3437 - val_acc: 0.8460\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 7s 697us/step - loss: 0.2810 - acc: 0.8765 - val_loss: 0.3472 - val_acc: 0.8430\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 7s 692us/step - loss: 0.2824 - acc: 0.8769 - val_loss: 0.3435 - val_acc: 0.8340\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2789 - acc: 0.8758 - val_loss: 0.3578 - val_acc: 0.8390\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 7s 687us/step - loss: 0.2824 - acc: 0.8771 - val_loss: 0.3542 - val_acc: 0.8360\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.2750 - acc: 0.8799 - val_loss: 0.3456 - val_acc: 0.8480\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.2811 - acc: 0.8761 - val_loss: 0.3529 - val_acc: 0.8400\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2738 - acc: 0.8755 - val_loss: 0.3469 - val_acc: 0.8390\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.2741 - acc: 0.8787 - val_loss: 0.3754 - val_acc: 0.8370\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 7s 692us/step - loss: 0.2744 - acc: 0.8797 - val_loss: 0.3682 - val_acc: 0.8280\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.2772 - acc: 0.8781 - val_loss: 0.3616 - val_acc: 0.8390\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 7s 718us/step - loss: 0.2729 - acc: 0.8792 - val_loss: 0.3477 - val_acc: 0.8440\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 7s 719us/step - loss: 0.2710 - acc: 0.8828 - val_loss: 0.3591 - val_acc: 0.8400\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 0.2678 - acc: 0.8821 - val_loss: 0.3646 - val_acc: 0.8400\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 7s 653us/step - loss: 0.2685 - acc: 0.8814 - val_loss: 0.3594 - val_acc: 0.8370\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 0.2689 - acc: 0.8832 - val_loss: 0.3585 - val_acc: 0.8330\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 7s 660us/step - loss: 0.2651 - acc: 0.8838 - val_loss: 0.3572 - val_acc: 0.8330\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 7s 695us/step - loss: 0.2670 - acc: 0.8794 - val_loss: 0.3771 - val_acc: 0.8340\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.2760 - acc: 0.8828 - val_loss: 0.3942 - val_acc: 0.8310\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.2673 - acc: 0.8821 - val_loss: 0.3759 - val_acc: 0.8400\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.2707 - acc: 0.8843 - val_loss: 0.3718 - val_acc: 0.8270\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 7s 675us/step - loss: 0.2647 - acc: 0.8817 - val_loss: 0.3884 - val_acc: 0.8390\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 7s 706us/step - loss: 0.2670 - acc: 0.8843 - val_loss: 0.3587 - val_acc: 0.8370\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.2606 - acc: 0.8846 - val_loss: 0.3627 - val_acc: 0.8330\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 7s 674us/step - loss: 0.2683 - acc: 0.8852 - val_loss: 0.3670 - val_acc: 0.8360\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 7s 679us/step - loss: 0.2570 - acc: 0.8877 - val_loss: 0.3605 - val_acc: 0.8320\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 7s 731us/step - loss: 0.2554 - acc: 0.8893 - val_loss: 0.3762 - val_acc: 0.8430\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 7s 683us/step - loss: 0.2604 - acc: 0.8872 - val_loss: 0.4028 - val_acc: 0.8360\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 8s 796us/step - loss: 0.2577 - acc: 0.8891 - val_loss: 0.3918 - val_acc: 0.8350\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.2545 - acc: 0.8887 - val_loss: 0.3779 - val_acc: 0.8380\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 8s 770us/step - loss: 0.2537 - acc: 0.8881 - val_loss: 0.3697 - val_acc: 0.8340\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.2545 - acc: 0.8889 - val_loss: 0.3949 - val_acc: 0.8350\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.2492 - acc: 0.8934 - val_loss: 0.3841 - val_acc: 0.8310\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.2582 - acc: 0.8884 - val_loss: 0.3846 - val_acc: 0.8360\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 0.2477 - acc: 0.8934 - val_loss: 0.3993 - val_acc: 0.8370\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.2535 - acc: 0.8918 - val_loss: 0.4133 - val_acc: 0.8380\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 7s 708us/step - loss: 0.2506 - acc: 0.8907 - val_loss: 0.3946 - val_acc: 0.8390\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.2452 - acc: 0.8913 - val_loss: 0.3902 - val_acc: 0.8330\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.2519 - acc: 0.8912 - val_loss: 0.3881 - val_acc: 0.8420\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2470 - acc: 0.8936 - val_loss: 0.4235 - val_acc: 0.8360\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.2437 - acc: 0.8956 - val_loss: 0.4273 - val_acc: 0.8370\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 7s 723us/step - loss: 0.2421 - acc: 0.8975 - val_loss: 0.4319 - val_acc: 0.8340\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 7s 729us/step - loss: 0.2435 - acc: 0.8945 - val_loss: 0.4070 - val_acc: 0.8380\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.2425 - acc: 0.8948 - val_loss: 0.4541 - val_acc: 0.8240\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.2428 - acc: 0.8948 - val_loss: 0.4108 - val_acc: 0.8400\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2374 - acc: 0.8989 - val_loss: 0.4138 - val_acc: 0.8370\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 7s 723us/step - loss: 0.2354 - acc: 0.8981 - val_loss: 0.4106 - val_acc: 0.8360\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.2380 - acc: 0.9024 - val_loss: 0.4353 - val_acc: 0.8360\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2327 - acc: 0.8999 - val_loss: 0.4222 - val_acc: 0.8330\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.2303 - acc: 0.9044 - val_loss: 0.4468 - val_acc: 0.8360\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.2305 - acc: 0.9015 - val_loss: 0.4547 - val_acc: 0.8290\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.2329 - acc: 0.9022 - val_loss: 0.4103 - val_acc: 0.8280\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2323 - acc: 0.9014 - val_loss: 0.4189 - val_acc: 0.8260\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.2314 - acc: 0.9034 - val_loss: 0.4539 - val_acc: 0.8300\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2249 - acc: 0.9024 - val_loss: 0.4195 - val_acc: 0.8360\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 710us/step - loss: 0.2254 - acc: 0.9048 - val_loss: 0.4321 - val_acc: 0.8380\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2282 - acc: 0.9044 - val_loss: 0.3986 - val_acc: 0.8410\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.2251 - acc: 0.9074 - val_loss: 0.4060 - val_acc: 0.8490\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.2177 - acc: 0.9088 - val_loss: 0.4062 - val_acc: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99999356\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "more examples from existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99999905\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
